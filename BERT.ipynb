{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-04-16T14:04:38.173506Z",
     "start_time": "2024-04-16T14:04:21.468079700Z"
    }
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
    "# from transformers import ElectraForPreTraining, ElectraTokenizerFast\n",
    "from transformers import RobertaTokenizerFast, TFRobertaForSequenceClassification, pipeline\n",
    "from transformers import AdamW"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "c6666741d3884bad9c1e6a69bc1d77c3"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\anaconda3\\envs\\SupportSystem\\lib\\site-packages\\huggingface_hub\\file_download.py:149: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\Admin\\.cache\\huggingface\\hub\\models--distilbert-base-uncased-finetuned-sst-2-english. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to see activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "data": {
      "text/plain": "config.json:   0%|          | 0.00/629 [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "f5bd2abff9ae4e17a5b2a102f918ebb9"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "0292780516cc475cba71110742e8b807"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "checkpoint = 'distilbert-base-uncased-finetuned-sst-2-english'\n",
    "tokenizer = AutoTokenizer.from_pretrained(checkpoint)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-16T14:22:36.527490600Z",
     "start_time": "2024-04-16T14:22:31.566568900Z"
    }
   },
   "id": "8e6fbc81adb5a3f",
   "execution_count": 6
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "train_data, test_data, train_labels, test_labels = train_test_split_part_dialog(\n",
    "    df['dialog'], df['initial_emotion_intensity'],\n",
    "    start_percentage=0, end_percentage=0.2,\n",
    "    test_start=0.2, test_end=0.4)\n",
    "# standard division on test and train\n",
    "train_dataset, val_dataset, train_labels, val_labels = train_test_split(train_data, train_labels, test_size=0.2,\n",
    "                                                                        random_state=1)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "15aee4ba737a4c90"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "text input must be of type `str` (single example), `List[str]` (batch or single pretokenized example) or `List[List[str]]` (batch of pretokenized examples).",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[7], line 1\u001B[0m\n\u001B[1;32m----> 1\u001B[0m inputs \u001B[38;5;241m=\u001B[39m \u001B[43mtokenizer\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdf\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mdialog\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mpadding\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtruncation\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mreturn_tensors\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m)\u001B[49m\n\u001B[0;32m      2\u001B[0m \u001B[38;5;28mprint\u001B[39m(inputs)\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\SupportSystem\\lib\\site-packages\\transformers\\tokenization_utils_base.py:2829\u001B[0m, in \u001B[0;36mPreTrainedTokenizerBase.__call__\u001B[1;34m(self, text, text_pair, text_target, text_pair_target, add_special_tokens, padding, truncation, max_length, stride, is_split_into_words, pad_to_multiple_of, return_tensors, return_token_type_ids, return_attention_mask, return_overflowing_tokens, return_special_tokens_mask, return_offsets_mapping, return_length, verbose, **kwargs)\u001B[0m\n\u001B[0;32m   2827\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_in_target_context_manager:\n\u001B[0;32m   2828\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_switch_to_input_mode()\n\u001B[1;32m-> 2829\u001B[0m     encodings \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_one\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtext\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtext\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtext_pair\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtext_pair\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mall_kwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   2830\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m text_target \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m   2831\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_switch_to_target_mode()\n",
      "File \u001B[1;32m~\\anaconda3\\envs\\SupportSystem\\lib\\site-packages\\transformers\\tokenization_utils_base.py:2887\u001B[0m, in \u001B[0;36mPreTrainedTokenizerBase._call_one\u001B[1;34m(self, text, text_pair, add_special_tokens, padding, truncation, max_length, stride, is_split_into_words, pad_to_multiple_of, return_tensors, return_token_type_ids, return_attention_mask, return_overflowing_tokens, return_special_tokens_mask, return_offsets_mapping, return_length, verbose, **kwargs)\u001B[0m\n\u001B[0;32m   2884\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;01mFalse\u001B[39;00m\n\u001B[0;32m   2886\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m _is_valid_text_input(text):\n\u001B[1;32m-> 2887\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[0;32m   2888\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtext input must be of type `str` (single example), `List[str]` (batch or single pretokenized example) \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m   2889\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mor `List[List[str]]` (batch of pretokenized examples).\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m   2890\u001B[0m     )\n\u001B[0;32m   2892\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m text_pair \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m _is_valid_text_input(text_pair):\n\u001B[0;32m   2893\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[0;32m   2894\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtext input must be of type `str` (single example), `List[str]` (batch or single pretokenized example) \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m   2895\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mor `List[List[str]]` (batch of pretokenized examples).\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m   2896\u001B[0m     )\n",
      "\u001B[1;31mValueError\u001B[0m: text input must be of type `str` (single example), `List[str]` (batch or single pretokenized example) or `List[List[str]]` (batch of pretokenized examples)."
     ]
    }
   ],
   "source": [
    "inputs = tokenizer(df['dialog'], padding=True, truncation=True, return_tensors=True)\n",
    "print(inputs)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-16T14:24:01.500752600Z",
     "start_time": "2024-04-16T14:23:58.745621200Z"
    }
   },
   "id": "7a960ee15ef84a2c",
   "execution_count": 7
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "72644a38b1f93dd5"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'label': 'disappointment', 'score': 0.46669498085975647}, {'label': 'sadness', 'score': 0.39849525690078735}, {'label': 'annoyance', 'score': 0.06806591153144836}, {'label': 'neutral', 'score': 0.057030171155929565}, {'label': 'disapproval', 'score': 0.044239308685064316}, {'label': 'nervousness', 'score': 0.014850764535367489}, {'label': 'realization', 'score': 0.014059898443520069}, {'label': 'approval', 'score': 0.0112674655392766}, {'label': 'joy', 'score': 0.00630340026691556}, {'label': 'remorse', 'score': 0.006221492309123278}, {'label': 'caring', 'score': 0.006029403302818537}, {'label': 'embarrassment', 'score': 0.005265483167022467}, {'label': 'anger', 'score': 0.004981426056474447}, {'label': 'disgust', 'score': 0.004259031731635332}, {'label': 'grief', 'score': 0.0040021371096372604}, {'label': 'confusion', 'score': 0.0033829212188720703}, {'label': 'relief', 'score': 0.003140498884022236}, {'label': 'desire', 'score': 0.00282747158780694}, {'label': 'admiration', 'score': 0.002815794898197055}, {'label': 'fear', 'score': 0.002707524225115776}, {'label': 'optimism', 'score': 0.0026164900045841932}, {'label': 'love', 'score': 0.002488391939550638}, {'label': 'excitement', 'score': 0.00244948104955256}, {'label': 'curiosity', 'score': 0.00237436406314373}, {'label': 'amusement', 'score': 0.001746696187183261}, {'label': 'surprise', 'score': 0.001452985918149352}, {'label': 'gratitude', 'score': 0.0006464758771471679}, {'label': 'pride', 'score': 0.00055424973834306}]\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "classifier = pipeline(task=\"text-classification\", model=\"SamLowe/roberta-base-go_emotions\", top_k=None)\n",
    "\n",
    "sentences = [\"I am not having a great day\"]\n",
    "\n",
    "model_outputs = classifier(sentences)\n",
    "print(model_outputs[0])\n",
    "# produces a list of dicts for each of the labels\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-04T14:35:20.772571900Z",
     "start_time": "2024-04-04T14:35:05.676550100Z"
    }
   },
   "id": "fe2d90f5dc9547b7",
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "model=\"siebert/sentiment-roberta-large-english\"\n",
    "sentiment_analysis = pipeline(\"sentiment-analysis\",model=model)\n",
    "#print(sentiment_analysis(\"I love this!\"))"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4245a03ad77c137a",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "867087e5880f4765",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Define hyperparameters\n",
    "num_epochs = 5\n",
    "batch_size = 5\n",
    "learning_rate = 2e-5"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "27e635f5bbe2327a",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# tokenizer = RobertaTokenizerFast.from_pretrained(\"arpanghoshal/EmoRoBERTa\")\n",
    "# model = TFRobertaForSequenceClassification.from_pretrained(\"arpanghoshal/EmoRoBERTa\")\n",
    "# \n",
    "# emotion = pipeline('sentiment-analysis', model='arpanghoshal/EmoRoBERTa')\n",
    "# emotion.to(device)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "390e62a85f2bc69f",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Load tokenizer and model\n",
    "# model = ElectraForPreTraining.from_pretrained(\"google/electra-base-discriminator\")\n",
    "# tokenizer = ElectraTokenizerFast.from_pretrained(\"google/electra-base-discriminator\")\n",
    "# num_classes = 5\n",
    "# #model = ElectraForSequenceClassification.from_pretrained('google/bio-electra-base-discriminator', num_labels=num_classes)\n",
    "# model.to(device)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ec33cee9481ed4f3",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Prepare data"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4f46c5ece223a35a"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def load_data(file_path):\n",
    "    with open(file_path, \"r\", encoding='utf-8') as file:\n",
    "        data = json.load(file)\n",
    "    return data\n",
    "\n",
    "dataset = load_data(\"ESConv.json\")\n",
    "dataframe = pd.DataFrame(dataset)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4708ffbc6515aa05",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def extract_dialog(dialog, start_percentage, end_percentage):\n",
    "    if isinstance(dialog, list):\n",
    "        seeker_contents = [item['content'] for item in dialog if item['speaker'] == 'seeker']\n",
    "        start_index = int(start_percentage * len(seeker_contents))\n",
    "        end_index = int(end_percentage * len(seeker_contents))\n",
    "        return ' '.join(seeker_contents[start_index:end_index])\n",
    "    elif isinstance(dialog, str):\n",
    "        sentences = dialog.split('.')\n",
    "        seeker_contents = [sentence for sentence in sentences] #[str, str, ..., str]\n",
    "        start_index = int(start_percentage * len(seeker_contents))\n",
    "        end_index = int(end_percentage * len(seeker_contents))\n",
    "        return seeker_contents[start_index:end_index]\n",
    "    else:\n",
    "        return None"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a6a84fd28617a76f",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "df = pd.DataFrame()\n",
    "df['dialog'] = dataframe['dialog'].apply(lambda x: extract_dialog(x, 0, 1)) #take whole dialog from seeker\n",
    "df['dialog'] = df['dialog'].apply(lambda x: ' '.join(x) if isinstance(x, list) else x)\n",
    "\n",
    "df['initial_emotion_intensity'] = dataframe['survey_score'].apply(\n",
    "    lambda x: x['seeker']['initial_emotion_intensity'])\n",
    "df['initial_emotion_intensity'].dropna(inplace=True)\n",
    "df['initial_emotion_intensity'] = df['initial_emotion_intensity'].astype(int)\n",
    "df['dialog'].dropna(inplace=True)\n",
    "#train_loader = DataLoader(df, batch_size=32, shuffle=True)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1461024ded85fbd6",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "df"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b94216b074252c9",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def train_test_split_part_dialog(dialog, labels, start_percentage, end_percentage, test_start, test_end):\n",
    "    train_data = []\n",
    "    test_data = []\n",
    "\n",
    "    if isinstance(labels, pd.Series):\n",
    "        labels = labels.tolist()\n",
    "\n",
    "    # Ensure labels are within the range of 0 to n_classes - 1\n",
    "    min_label = min(labels)\n",
    "    train_labels = labels\n",
    "    test_labels = labels\n",
    "\n",
    "    if isinstance(dialog, list):\n",
    "        for conv in dialog:\n",
    "            seeker_contents = [item['content'] for item in conv if item['speaker'] == 'seeker']\n",
    "            start_index = int(start_percentage * len(seeker_contents))\n",
    "            end_index = int(end_percentage * len(seeker_contents))\n",
    "            test_start_index = int(test_start * len(seeker_contents))\n",
    "            test_end_index = int(test_end * len(seeker_contents))\n",
    "\n",
    "            train_data.extend(seeker_contents[start_index:end_index])\n",
    "            test_data.extend(seeker_contents[test_start_index:test_end_index])\n",
    "\n",
    "    elif isinstance(dialog, str):\n",
    "        sentences = dialog.split('.')\n",
    "        seeker_contents = [sentence.strip() for sentence in sentences]\n",
    "        start_index = int(start_percentage * len(seeker_contents))\n",
    "        end_index = int(end_percentage * len(seeker_contents))\n",
    "        test_start_index = int(test_start * len(seeker_contents))\n",
    "        test_end_index = int(test_end * len(seeker_contents))\n",
    "\n",
    "        train_data = seeker_contents[start_index:end_index]\n",
    "        test_data = seeker_contents[test_start_index:test_end_index]\n",
    "\n",
    "    elif isinstance(dialog, pd.Series):\n",
    "        for conv in dialog:\n",
    "            seeker_contents = conv\n",
    "            start_index = int(start_percentage * len(seeker_contents))\n",
    "            end_index = int(end_percentage * len(seeker_contents))\n",
    "            test_start_index = int(test_start * len(seeker_contents))\n",
    "            test_end_index = int(test_end * len(seeker_contents))\n",
    "\n",
    "            # train_data.append((seeker_contents[start_index:end_index],))  # Append as tuple\n",
    "            # test_data.append((seeker_contents[test_start_index:test_end_index],))  # Append as tuple\n",
    "            train_data.append(' '.join(seeker_contents[start_index:end_index]))\n",
    "            test_data.append(' '.join(seeker_contents[test_start_index:test_end_index]))\n",
    "\n",
    "    return tuple(train_data), tuple(test_data), train_labels, test_labels"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b8256053aca606ca",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "train_data, test_data, train_labels, test_labels = train_test_split_part_dialog(\n",
    "    df['dialog'], df['initial_emotion_intensity'],\n",
    "    start_percentage=0, end_percentage=0.2,\n",
    "    test_start=0.2, test_end=0.4)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5ad36e544588ca82",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# standard division on test and train\n",
    "train_dataset, val_dataset, train_labels, val_labels = train_test_split(train_data, train_labels, test_size=0.2, random_state=1)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b170015d11803db1",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    " "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a32dbf60a89ac92f",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "for i in train_dataset:\n",
    "    print(i)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a76fa72fc8e491a8",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_dataloader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f809fa09533179e4",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "for i, batch in train_dataloader:\n",
    "    print(\"Texts:\", batch)\n",
    "    print(\"Labels:\", i)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2fae95b044cc0f5c",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Define optimizer and loss function\n",
    "optimizer = AdamW(model.parameters(), lr=learning_rate, no_deprecation_warning=True)\n",
    "loss_fn = torch.nn.CrossEntropyLoss()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5b9c2513a16e87d2",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    total_correct = 0\n",
    "    total_samples = 0\n",
    "\n",
    "    for i, batch in train_dataloader:\n",
    "        print('Training...')\n",
    "        inputs = tokenizer(batch, padding=True, truncation=True, return_tensors='pt')\n",
    "        inputs = {k: v.to(device) for k, v in inputs.items()}\n",
    "        labels = i.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(**inputs)\n",
    "        logits = outputs.logits\n",
    "        loss = loss_fn(logits, labels)\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "        _, predicted_labels = torch.max(logits, dim=1)\n",
    "        total_correct += (predicted_labels == labels).sum().item()\n",
    "        total_samples += labels.size(0)\n",
    "        print('Stop Training...')\n",
    "\n",
    "    train_loss = total_loss / len(train_dataloader)\n",
    "    train_accuracy = total_correct / total_samples\n",
    "\n",
    "    # Evaluation on validation set\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        total_val_loss = 0\n",
    "        total_val_correct = 0\n",
    "        total_val_samples = 0\n",
    "\n",
    "        for i, batch in val_dataloader:\n",
    "            print('Validation...')\n",
    "            inputs = tokenizer(batch, padding=True, truncation=True, return_tensors='pt')\n",
    "            inputs = {k: v.to(device) for k, v in inputs.items()}\n",
    "            labels = i.to(device)\n",
    "\n",
    "            outputs = model(**inputs)\n",
    "            logits = outputs.logits\n",
    "            loss = loss_fn(logits, labels)\n",
    "\n",
    "            total_val_loss += loss.item()\n",
    "            _, predicted_labels = torch.max(logits, dim=1)\n",
    "            total_val_correct += (predicted_labels == labels).sum().item()\n",
    "            total_val_samples += labels.size(0)\n",
    "\n",
    "        val_loss = total_val_loss / len(val_dataloader)\n",
    "        val_accuracy = total_val_correct / total_val_samples\n",
    "\n",
    "    # Print epoch results\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs}:\")\n",
    "    print(f\"Train Loss: {train_loss:.4f} - Train Accuracy: {train_accuracy:.4f}\")\n",
    "    print(f\"Validation Loss: {val_loss:.4f} - Validation Accuracy: {val_accuracy:.4f}\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9aa20b34796e9b8e",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    " "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "92379dd64d998aff"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
